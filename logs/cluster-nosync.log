
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Value in main function False
Input batch shape: images: (256, 256, 256, 3) labels: (256,)
Value just before calling alexnetmodes False
num_classes: 1000
Value inside distribute function : False
total_num_examples: 12288
Value of num_replicas inside train function : 0
fake_data/input_producer/FIFOQueueV2
fake_data/input_producer_1/FIFOQueueV2
4 threads started for queue
2019-04-18 16:06:21.927987: step 0, loss = 12.29 (53.5 examples/sec; 4.781 sec/batch)
2019-04-18 16:06:26.559248: step 1, loss = 3.91 (68.0 examples/sec; 3.763 sec/batch)
2019-04-18 16:06:30.434847: step 2, loss = 3.91 (66.2 examples/sec; 3.869 sec/batch)
2019-04-18 16:06:34.196122: step 3, loss = 3.91 (68.2 examples/sec; 3.755 sec/batch)
2019-04-18 16:06:38.391200: step 4, loss = 3.91 (61.1 examples/sec; 4.187 sec/batch)
2019-04-18 16:06:42.232471: step 5, loss = 3.91 (66.8 examples/sec; 3.834 sec/batch)
2019-04-18 16:06:46.068220: step 6, loss = 3.91 (66.9 examples/sec; 3.829 sec/batch)
2019-04-18 16:06:49.771193: step 7, loss = 3.91 (69.3 examples/sec; 3.696 sec/batch)
2019-04-18 16:06:53.439533: step 8, loss = 3.91 (69.9 examples/sec; 3.664 sec/batch)
2019-04-18 16:06:57.195448: step 9, loss = 3.91 (68.3 examples/sec; 3.749 sec/batch)
2019-04-18 16:07:00.851932: step 10, loss = 3.91 (70.1 examples/sec; 3.652 sec/batch)
2019-04-18 16:07:04.891540: step 11, loss = 3.91 (63.5 examples/sec; 4.033 sec/batch)
2019-04-18 16:07:08.638881: step 12, loss = 3.91 (68.4 examples/sec; 3.741 sec/batch)
2019-04-18 16:07:12.404017: step 13, loss = 3.91 (68.1 examples/sec; 3.758 sec/batch)
2019-04-18 16:07:16.297630: step 14, loss = 3.91 (65.9 examples/sec; 3.887 sec/batch)
2019-04-18 16:07:20.450176: step 15, loss = 3.91 (61.7 examples/sec; 4.146 sec/batch)
2019-04-18 16:07:24.143851: step 16, loss = 3.91 (69.4 examples/sec; 3.687 sec/batch)
2019-04-18 16:07:27.928341: step 17, loss = 3.91 (67.8 examples/sec; 3.778 sec/batch)
2019-04-18 16:07:31.725446: step 18, loss = 3.91 (67.5 examples/sec; 3.793 sec/batch)
2019-04-18 16:07:35.401168: step 19, loss = 3.91 (69.8 examples/sec; 3.669 sec/batch)
2019-04-18 16:07:39.332601: step 20, loss = 3.91 (65.2 examples/sec; 3.926 sec/batch)
2019-04-18 16:07:43.204380: step 21, loss = 3.91 (66.2 examples/sec; 3.865 sec/batch)
2019-04-18 16:07:46.875158: step 22, loss = 3.91 (69.9 examples/sec; 3.664 sec/batch)
2019-04-18 16:07:50.688784: step 23, loss = 3.91 (67.2 examples/sec; 3.807 sec/batch)
2019-04-18 16:07:54.489410: step 24, loss = 3.91 (67.5 examples/sec; 3.794 sec/batch)
2019-04-18 16:07:58.230795: step 25, loss = 3.91 (68.5 examples/sec; 3.735 sec/batch)
2019-04-18 16:08:02.024972: step 26, loss = 3.91 (67.6 examples/sec; 3.788 sec/batch)
2019-04-18 16:08:05.786894: step 27, loss = 3.91 (68.2 examples/sec; 3.755 sec/batch)
2019-04-18 16:08:09.857308: step 28, loss = 3.91 (63.0 examples/sec; 4.064 sec/batch)
2019-04-18 16:08:13.878769: step 29, loss = 3.91 (63.8 examples/sec; 4.015 sec/batch)
2019-04-18 16:08:17.584803: step 30, loss = 3.91 (69.2 examples/sec; 3.699 sec/batch)
2019-04-18 16:08:21.766798: step 31, loss = 3.91 (61.3 examples/sec; 4.175 sec/batch)
2019-04-18 16:08:25.782107: step 32, loss = 3.91 (63.9 examples/sec; 4.009 sec/batch)
2019-04-18 16:08:29.593261: step 33, loss = 3.91 (67.3 examples/sec; 3.805 sec/batch)
2019-04-18 16:08:33.382451: step 34, loss = 3.91 (67.6 examples/sec; 3.785 sec/batch)
2019-04-18 16:08:37.201520: step 35, loss = 3.91 (67.2 examples/sec; 3.812 sec/batch)
2019-04-18 16:08:40.856104: step 36, loss = 3.91 (70.2 examples/sec; 3.648 sec/batch)
2019-04-18 16:08:45.062256: step 37, loss = 3.91 (61.0 examples/sec; 4.199 sec/batch)
2019-04-18 16:08:49.105762: step 38, loss = 3.91 (63.4 examples/sec; 4.037 sec/batch)
2019-04-18 16:08:52.931985: step 39, loss = 3.91 (67.0 examples/sec; 3.820 sec/batch)
2019-04-18 16:08:56.737925: step 40, loss = 3.91 (67.4 examples/sec; 3.799 sec/batch)
2019-04-18 16:09:00.568093: step 41, loss = 3.91 (66.9 examples/sec; 3.825 sec/batch)
2019-04-18 16:09:04.354199: step 42, loss = 3.91 (67.7 examples/sec; 3.779 sec/batch)
2019-04-18 16:09:08.223558: step 43, loss = 3.91 (66.3 examples/sec; 3.863 sec/batch)
2019-04-18 16:09:11.966450: step 44, loss = 3.91 (68.5 examples/sec; 3.738 sec/batch)
2019-04-18 16:09:15.665137: step 45, loss = 3.91 (69.3 examples/sec; 3.692 sec/batch)
2019-04-18 16:09:19.534486: step 46, loss = 3.91 (66.3 examples/sec; 3.863 sec/batch)
2019-04-18 16:09:23.361787: step 47, loss = 3.91 (67.0 examples/sec; 3.821 sec/batch)
Average 66.6 examples/sec
