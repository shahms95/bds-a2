
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Value in main function False
Input batch shape: images: (384, 256, 256, 3) labels: (384,)
Value just before calling alexnetmodes False
num_classes: 1000
Value inside distribute function : False
total_num_examples: 12288
Value of num_replicas inside train function : 0
fake_data/input_producer/FIFOQueueV2
fake_data/input_producer_1/FIFOQueueV2
4 threads started for queue
2019-04-18 16:09:59.562101: step 0, loss = 14.47 (72.1 examples/sec; 5.328 sec/batch)
2019-04-18 16:10:04.985592: step 1, loss = 5.86 (93.6 examples/sec; 4.103 sec/batch)
2019-04-18 16:10:09.142436: step 2, loss = 5.86 (92.5 examples/sec; 4.151 sec/batch)
2019-04-18 16:10:13.404477: step 3, loss = 5.86 (90.3 examples/sec; 4.253 sec/batch)
2019-04-18 16:10:17.638401: step 4, loss = 5.86 (90.9 examples/sec; 4.226 sec/batch)
2019-04-18 16:10:21.785366: step 5, loss = 5.86 (92.7 examples/sec; 4.141 sec/batch)
2019-04-18 16:10:25.983782: step 6, loss = 5.86 (91.6 examples/sec; 4.190 sec/batch)
2019-04-18 16:10:30.127699: step 7, loss = 5.86 (92.9 examples/sec; 4.134 sec/batch)
2019-04-18 16:10:34.461940: step 8, loss = 5.86 (88.8 examples/sec; 4.325 sec/batch)
2019-04-18 16:10:38.564157: step 9, loss = 5.86 (93.8 examples/sec; 4.093 sec/batch)
2019-04-18 16:10:43.177465: step 10, loss = 5.86 (83.4 examples/sec; 4.604 sec/batch)
2019-04-18 16:10:47.349203: step 11, loss = 5.86 (92.2 examples/sec; 4.163 sec/batch)
2019-04-18 16:10:51.605355: step 12, loss = 5.86 (90.4 examples/sec; 4.247 sec/batch)
2019-04-18 16:10:55.627422: step 13, loss = 5.86 (95.7 examples/sec; 4.012 sec/batch)
2019-04-18 16:10:59.735775: step 14, loss = 5.86 (93.7 examples/sec; 4.099 sec/batch)
2019-04-18 16:11:03.906434: step 15, loss = 5.86 (92.3 examples/sec; 4.161 sec/batch)
2019-04-18 16:11:08.017180: step 16, loss = 5.86 (93.6 examples/sec; 4.101 sec/batch)
2019-04-18 16:11:12.257476: step 17, loss = 5.86 (90.8 examples/sec; 4.231 sec/batch)
2019-04-18 16:11:16.397845: step 18, loss = 5.86 (93.0 examples/sec; 4.131 sec/batch)
2019-04-18 16:11:20.498591: step 19, loss = 5.86 (93.9 examples/sec; 4.088 sec/batch)
2019-04-18 16:11:24.541019: step 20, loss = 5.86 (95.2 examples/sec; 4.034 sec/batch)
2019-04-18 16:11:28.496631: step 21, loss = 5.86 (97.3 examples/sec; 3.945 sec/batch)
2019-04-18 16:11:32.648993: step 22, loss = 5.86 (92.7 examples/sec; 4.143 sec/batch)
2019-04-18 16:11:36.683558: step 23, loss = 5.86 (95.4 examples/sec; 4.025 sec/batch)
2019-04-18 16:11:40.789802: step 24, loss = 5.86 (93.7 examples/sec; 4.097 sec/batch)
2019-04-18 16:11:44.949541: step 25, loss = 5.86 (92.5 examples/sec; 4.150 sec/batch)
2019-04-18 16:11:49.027342: step 26, loss = 5.86 (94.4 examples/sec; 4.068 sec/batch)
2019-04-18 16:11:53.148410: step 27, loss = 5.86 (93.4 examples/sec; 4.112 sec/batch)
2019-04-18 16:11:57.217167: step 28, loss = 5.86 (94.6 examples/sec; 4.059 sec/batch)
2019-04-18 16:12:01.264755: step 29, loss = 5.86 (95.1 examples/sec; 4.038 sec/batch)
2019-04-18 16:12:05.445448: step 30, loss = 5.86 (92.1 examples/sec; 4.171 sec/batch)
2019-04-18 16:12:09.961516: step 31, loss = 5.86 (85.2 examples/sec; 4.506 sec/batch)
Average 91.9 examples/sec
