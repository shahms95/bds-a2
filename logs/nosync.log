
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Value in main function False
Input batch shape: images: (384, 256, 256, 3) labels: (384,)
Value just before calling alexnetmodes False
num_classes: 1000
Value inside distribute function : False
total_num_examples: 12288
Value of num_replicas inside train function : 0
fake_data/input_producer/FIFOQueueV2
fake_data/input_producer_1/FIFOQueueV2
4 threads started for queue
2019-04-18 15:16:07.808668: step 0, loss = 15.84 (78.6 examples/sec; 4.887 sec/batch)
2019-04-18 15:16:13.473113: step 1, loss = 5.87 (89.0 examples/sec; 4.316 sec/batch)
2019-04-18 15:16:17.758504: step 2, loss = 5.87 (89.8 examples/sec; 4.276 sec/batch)
2019-04-18 15:16:22.017411: step 3, loss = 5.87 (90.4 examples/sec; 4.250 sec/batch)
2019-04-18 15:16:26.663229: step 4, loss = 5.87 (82.8 examples/sec; 4.636 sec/batch)
2019-04-18 15:16:30.962346: step 5, loss = 5.87 (89.5 examples/sec; 4.290 sec/batch)
2019-04-18 15:16:35.110863: step 6, loss = 5.87 (92.8 examples/sec; 4.139 sec/batch)
2019-04-18 15:16:39.329020: step 7, loss = 5.87 (91.2 examples/sec; 4.209 sec/batch)
2019-04-18 15:16:43.509781: step 8, loss = 5.87 (92.1 examples/sec; 4.171 sec/batch)
2019-04-18 15:16:47.668506: step 9, loss = 5.87 (92.6 examples/sec; 4.149 sec/batch)
2019-04-18 15:16:51.837880: step 10, loss = 5.87 (92.3 examples/sec; 4.160 sec/batch)
2019-04-18 15:16:56.163010: step 11, loss = 5.87 (89.0 examples/sec; 4.315 sec/batch)
2019-04-18 15:17:00.280583: step 12, loss = 5.87 (93.5 examples/sec; 4.108 sec/batch)
2019-04-18 15:17:04.456431: step 13, loss = 5.87 (92.1 examples/sec; 4.168 sec/batch)
2019-04-18 15:17:08.590162: step 14, loss = 5.87 (93.1 examples/sec; 4.124 sec/batch)
2019-04-18 15:17:12.917266: step 15, loss = 5.87 (88.9 examples/sec; 4.317 sec/batch)
2019-04-18 15:17:17.051770: step 16, loss = 5.87 (93.1 examples/sec; 4.125 sec/batch)
2019-04-18 15:17:21.095886: step 17, loss = 5.87 (95.1 examples/sec; 4.038 sec/batch)
2019-04-18 15:17:25.092678: step 18, loss = 5.87 (96.3 examples/sec; 3.987 sec/batch)
2019-04-18 15:17:29.225144: step 19, loss = 5.87 (93.1 examples/sec; 4.126 sec/batch)
2019-04-18 15:17:33.363135: step 20, loss = 5.87 (93.1 examples/sec; 4.127 sec/batch)
2019-04-18 15:17:37.512240: step 21, loss = 5.87 (92.8 examples/sec; 4.138 sec/batch)
2019-04-18 15:17:41.748468: step 22, loss = 5.86 (90.8 examples/sec; 4.230 sec/batch)
2019-04-18 15:17:45.845381: step 23, loss = 5.86 (94.0 examples/sec; 4.087 sec/batch)
2019-04-18 15:17:49.987958: step 24, loss = 5.86 (92.9 examples/sec; 4.133 sec/batch)
2019-04-18 15:17:54.552811: step 25, loss = 5.86 (84.3 examples/sec; 4.555 sec/batch)
2019-04-18 15:17:58.702283: step 26, loss = 5.86 (92.7 examples/sec; 4.143 sec/batch)
2019-04-18 15:18:02.880764: step 27, loss = 5.86 (92.1 examples/sec; 4.169 sec/batch)
2019-04-18 15:18:06.972780: step 28, loss = 5.86 (94.1 examples/sec; 4.082 sec/batch)
2019-04-18 15:18:11.134737: step 29, loss = 5.86 (92.5 examples/sec; 4.152 sec/batch)
2019-04-18 15:18:15.221757: step 30, loss = 5.86 (94.2 examples/sec; 4.077 sec/batch)
2019-04-18 15:18:19.243699: step 31, loss = 5.86 (95.7 examples/sec; 4.012 sec/batch)
Average 91.4 examples/sec
